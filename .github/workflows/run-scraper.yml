name: Run Amazon INF Scraper

on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

  # Runs the scraper on a schedule.
  # This example runs at 8:00 AM UTC every day.
  # Use https://crontab.guru/ to customize the schedule.
  schedule:
    - cron: '0 8 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15 # Set a timeout to prevent runaway jobs

    steps:
      - name: 1. Check out repository code
        uses: actions/checkout@v4

      - name: 2. Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: 3. Install Python dependencies
        run: pip install -r requirements.txt

      - name: 4. Install Playwright browsers
        run: python -m playwright install --with-deps chromium

      - name: 5. Create config.json from secrets
        run: |
          echo '{
            "debug": false,
            "login_url": "https://sellercentral.amazon.co.uk/",
            "login_email": "${{ secrets.LOGIN_EMAIL }}",
            "login_password": "${{ secrets.LOGIN_PASSWORD }}",
            "otp_secret_key": "${{ secrets.OTP_SECRET_KEY }}",
            "inf_webhook_url": "${{ secrets.INF_WEBHOOK_URL }}",
            "target_store": {
              "store_name": "${{ secrets.TARGET_STORE_NAME }}",
              "merchant_id": "${{ secrets.TARGET_MERCHANT_ID }}",
              "marketplace_id": "${{ secrets.TARGET_MARKETPLACE_ID }}"
            }
          }' > config.json

      - name: 6. Run the scraper script
        run: python inf.py

      - name: 7. Upload logs and screenshots on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs-and-output
          path: |
            inf_app.log
            output/